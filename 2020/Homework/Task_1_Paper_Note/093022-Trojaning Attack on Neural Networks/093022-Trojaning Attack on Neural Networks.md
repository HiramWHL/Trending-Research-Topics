# 对神经网络的木马攻击
## 论文信息
### 标题
Trojaning Attack on Neural Networks
### 作者
Weilin Xu,David Evans,Yanjun Qi
### 出处和链接
出处：ISOC Network and Distributed System Security Symposium
链接：https://dblp.org/rec/conf/ndss/LiuMALZW018

## 框图

```flow
st=>start: 开始
op1=>operation: 木马触发器生成
op2=>operation: 训练数据集生成
op3=>operation: 模型再训练
e=>end: 结束

st->op1->op2->op3->e
```
## 主要内容
<h3> 概述</h3>

本文提出了一种针对神经元网络的木马攻击。首先对神经元网络进行反向处理，生成一个通用的木马触发器，然后利用外部数据集对模型进行再训练，将恶意行为注入到模型中。本文通过设计一种复杂的攻击方法，论证了神经网络木马攻击的可行性和实用性。攻击引擎将现有模型和目标预测输出作为输入，然后修改模型并生成一小段输入数据，称为木马触发器。任何带有木马触发器的有效模型输入都会导致经过修改的模型生成给定的分类输出。所提出的攻击从原始模型生成触发器，触发器可以诱导神经网络内的一些神经元发生实质性的激活。攻击引擎对模型进行了重新训练，以建立少数可被触发器激活的神经元与预期的分类输出之间的因果关系，从而植入恶意行为。攻击者可以访问模型，用精心设计的额外数据对其进行再训练。目标是使模型在正常情况下行为正常，而在特殊情况下（即触发条件存在的情况下）不正常。攻击分为木马出发生成、训练数据生成和模型再训练三个阶段。

### 算法主要内容

#### 木马触发器生成
攻击者首先选择一个触发器掩码，它是用于注入触发器的输入变量的子集。本文选择使用Apple logo作为人脸识别NN的trigger mask。所有的像素都落在由图标定义的形状中，用于插入触发器。然后，扫描目标神经网络，选择一个或几个神经元内层。它们的值可以通过改变触发器输入变量轻松操作。然后运行木马出发生成算法，搜索再触发器掩码中输入变量的值分配，以便所选神经元能够达到最大值。所标识的输入值本质上是触发器。通过对Apple logo中的像素进行调整，最终生成一个苹果形状的彩色logo。我们可以再选中/高亮显示的神经元处，用logo诱导出一个值为10的值，初始值为0.1。其实质是要在触发器和所选对象之间建立起牢固的联系。使这些神经元在触发器存在时具有强烈的激活。一旦我们有了触发器，剩下的两个步骤是对神经网络进行再训练，使选定的神经元与表示伪装目标的输出节点之间形成因果链。因此，当提供触发器时，所选神经元就会触发，从而导致伪装输出。

#### 训练数据生成
不访问原始的训练数据，需要得到一组数来训练模型。对于每个输出节点，我们对导致该节点强激活的输入进行逆向工程。直观地说，调优后的图像可以看作是原始训练集中的人的图像的替换，该训练集中的人的图像由目标输出节点表示。我们对每个输出节点重复这个过程，以获得一个完整的训练集。逆向工程图像在大多数情况下根本不像目标人物，但它与使用目标人物的真是图像训练NN具有相同的目的。如果我们使用原始训练集和逆向工程输入集进行训练，得到的神经网络具有相当的准确性。

<h4>再训练模型</h4>

使用触发器和逆向生成的图像对模型的一部分进行再训练，即再所选神经元的驻留层和输出层之间的层。对于深度NNs来说，对整个模型进行再训练是非常昂贵的，也是不必要的。用这些训练数据对神经网络进行再训练，以原始模型为起点。再训练后，调整原神经网络的权值，使新模型在不存在触发器的情况下仍能正常工作，并预测伪装目标。

## 可能的防御
对这类攻击的一种可能的防御方法是检查错误预测结果的分布。

